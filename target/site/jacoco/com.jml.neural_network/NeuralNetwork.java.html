<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>NeuralNetwork.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">java-machine-learning</a> &gt; <a href="index.source.html" class="el_package">com.jml.neural_network</a> &gt; <span class="el_source">NeuralNetwork.java</span></div><h1>NeuralNetwork.java</h1><pre class="source lang-java linenums">package com.jml.neural_network;

import com.jml.core.Model;
import com.jml.core.ModelTypes;
import com.jml.neural_network.layers.Layer;
import com.jml.optimizers.Optimizer;
import linalg.Matrix;

import java.util.List;

public class NeuralNetwork extends Model&lt;double[][], double[][]&gt; {

<span class="nc" id="L13">    protected String MODEL_TYPE = ModelTypes.NEURAL_NETWORK.toString();</span>
    private List&lt;Layer&gt; layers;


    /**
     * Constructs a neural network with the specified hyper-parameters.
     *
     * @param learningRate The learning rate to be using during optimization.
     * @param epochs The number of epochs to train the network for.
     * @param batchSize The batch size to use during training.
     * @param threshold The threshold for the loss to stop early. If the loss drops below this threshold before the
     *                  specified number of epochs has been reached, the training will stop early.
     * @param optim The {@link com.jml.optimizers.Optimizer optimizer} to use during training. If you wish to define a
     *              {@link com.jml.optimizers.Scheduler scheduler}, it must be defined as part of the optimizer.
     */
<span class="nc" id="L28">    public NeuralNetwork(double learningRate, double epochs, double batchSize, double threshold, Optimizer optim) {</span>
        // TODO: Auto-generated method stub
<span class="nc" id="L30">    }</span>

    /**
     * Fits or trains the model with the given features and targets.
     *
     * @param features The features of the training set.
     * @param targets  The targets of the training set.
     * @return Returns details of the fitting / training process.
     * @throws IllegalArgumentException Can be thrown for the following reasons&lt;br&gt;
     *                                  - If key, value pairs in &lt;code&gt;args&lt;/code&gt; are unspecified or invalid arguments. &lt;br&gt;
     *                                  - If the features and targets are not correctly sized per the specification when the model was
     *                                  compiled.
     */
    @Override
    public NeuralNetwork fit(double[][] features, double[][] targets) {
        // TODO: Auto-generated method stub
<span class="nc" id="L46">        return null;</span>
    }


    /**
     * Computes the forward pass of the neural network.&lt;br&gt;
     * The forward pass computes the values for each layer based on an input.
     */
    protected Matrix feedForward(Matrix inputs) {
<span class="nc" id="L55">        Matrix currentInput = new Matrix(inputs); // TODO: Rename the variable. Since it is really the output of the model</span>

<span class="nc bnc" id="L57" title="All 2 branches missed.">        for(Layer layer : layers) { // Feeds the input through all layers.</span>
<span class="nc" id="L58">            currentInput = layer.forward(currentInput);</span>
<span class="nc" id="L59">        }</span>

<span class="nc" id="L61">        return currentInput;</span>
    }


    /**
     * Computes the backward pass of the neural network and updates weights.
     * The backwards pass updates the weights of each layer in an attempt to decrease the loss of the forward pass.
     * This is done by back-propagation and gradient descent.
     */
    protected void back() {
        // TODO: Auto-generated method stub
<span class="nc" id="L72">    }</span>


    /**
     * Uses fitted/trained model to make predictions on features.
     *
     * @param features The features to make predictions on.
     * @return The models predicted labels.
     * @throws IllegalArgumentException Thrown if the features are not correctly sized per
     *                                  the specification when the model was compiled.
     */
    @Override
    public double[][] predict(double[][] features) {
        // TODO: Auto-generated method stub
<span class="nc" id="L86">        return new double[0][];</span>
    }


    /**
     * {@inheritDoc}
     */
    @Override
    public Matrix predict(Matrix X, Matrix w) {
        // TODO: Auto-generated method stub.
<span class="nc" id="L96">        return null;</span>
    }

    /**
     * Gets the parameters of the trained model.
     *
     * @return A matrix containing the parameters of the trained model.
     */
    @Override
    public Matrix getParams() {
<span class="nc" id="L106">        return null;</span>
    }


    /**
     * Adds specified layer to the network.
     *
     * @param layer Layer to add to the neural network.
     */
    public void add(Layer layer) {
<span class="nc bnc" id="L116" title="All 2 branches missed.">        if(layers.size() == 0) { // Then this is the first layer and the input dimension must be defined</span>
<span class="nc bnc" id="L117" title="All 2 branches missed.">            if(layer.getInDim() == -1) {</span>
<span class="nc" id="L118">                throw new IllegalArgumentException(&quot;First layer must have input dimension defined.&quot;);</span>
            }

        } else { // Then this is not the first layer.
<span class="nc bnc" id="L122" title="All 2 branches missed.">            if(layer.getInDim() == -1) { // Then the input dimension is to be inferred from the previous layer.</span>
<span class="nc" id="L123">                layer.updateInDim(layers.get(layers.size()-1).getOutDim()); // Infer the input dimension from previous layer</span>

            } else {
<span class="nc bnc" id="L126" title="All 2 branches missed.">                if(layer.getInDim() != layers.get(layers.size()-1).getOutDim()) {</span>
<span class="nc" id="L127">                    throw new IllegalArgumentException(&quot;Layers input dimension of &quot; + layer.getInDim() +</span>
<span class="nc" id="L128">                            &quot; is inconsistent with the previous layers output dimension of &quot; + layers.get(layers.size()-1).getOutDim() + &quot;.&quot; +</span>
                            &quot; Layers input dimension must match the output dimension of the previous layer.&quot;);
                }

            }

        }

<span class="nc" id="L136">        layers.add(layer);</span>
<span class="nc" id="L137">    }</span>


    /**
     * Saves a trained model to the specified file path.
     *
     * @param filePath File path, including extension, to save fitted / trained model to.
     */
    @Override
    public void saveModel(String filePath) {
        // TODO: Auto-generated method stub
<span class="nc" id="L148">    }</span>


    /**
     * Forms a string of the important aspects of the model.&lt;br&gt;
     * same as {@link #toString()}
     *
     * @return Details of model as string.
     */
    @Override
    public String getDetails() {
        // TODO: Auto-generated method stub
<span class="nc" id="L160">        return null;</span>
    }


    /**
     * Forms a string of the important aspects of the model.
     *
     * @return String representation of model.
     */
    @Override
    public String toString() {
        // TODO: Auto-generated method stub
<span class="nc" id="L172">        return &quot;&quot;;</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.7.202105040129</span></div></body></html>