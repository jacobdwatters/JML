<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>Gradient.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">java-machine-learning</a> &gt; <a href="index.source.html" class="el_package">com.jml.core</a> &gt; <span class="el_source">Gradient.java</span></div><h1>Gradient.java</h1><pre class="source lang-java linenums">package com.jml.core;

import com.jml.losses.Function;
import com.jml.losses.LossFunctions;
import linalg.Matrix;

public class Gradient {

<span class="nc" id="L9">    private static double h = 0.5e-8;</span>

<span class="nc" id="L11">    private Gradient() {</span>
<span class="nc" id="L12">        throw new IllegalStateException(&quot;Utility method cannot be instantiated.&quot;);</span>
    }


    /**
     * Numerically computes the gradient of a loss function for a specified model.
     *
     * @param w Parameters of the model.
     * @param X Features of the dataset.
     * @param y Targets of the dataset.
     * @param F Function to compute gradient of.
     * @param model Model to use for gradient computation.
     * @return Gradient with respect to w for the specified function.
     */
    public static Matrix compute(Matrix w, Matrix X, Matrix y, Function F, Model model) {

<span class="nc" id="L28">        Matrix grad = new Matrix(w.shape());</span>

        // A diagonal matrix containing the value of h along the diagonal.
<span class="nc" id="L31">        Matrix H = Matrix.I(w.numRows()).scalMult(h);</span>
<span class="nc" id="L32">        Matrix functionValue = F.compute(w, X, y, model);</span>

<span class="nc bnc" id="L34" title="All 2 branches missed.">        for(int i=0; i&lt;w.numRows(); i++) { // Compute partial derivative for each w_i in w</span>

<span class="nc" id="L36">            Matrix partial = F.compute(</span>
<span class="nc" id="L37">                    w.add(H.getColAsVector(i)), X, y, model).sub(</span>
                    functionValue
<span class="nc" id="L39">            ).scalDiv(h);</span>

            // Set the gradient at the given index to be the computed partial derivative.
<span class="nc" id="L42">            grad.set(partial.getAsDouble(0, 0), i, 0);</span>
        }

<span class="nc" id="L45">        return grad;</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.7.202105040129</span></div></body></html>