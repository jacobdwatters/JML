<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>Relu.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">java-machine-learning</a> &gt; <a href="index.source.html" class="el_package">com.jml.neural_network.activations</a> &gt; <span class="el_source">Relu.java</span></div><h1>Relu.java</h1><pre class="source lang-java linenums">package com.jml.neural_network.activations;

import linalg.Matrix;


/**
 * The ReLU (Rectified Linear Unit) activation function. That is f(x)=max(0, x)
 */
<span class="nc" id="L9">class Relu implements Activation {</span>

<span class="nc" id="L11">    public final String NAME = &quot;ReLU&quot;;</span>

    /**
     * Applies the ReLU activation function to a matrix element-wise.
     *
     * @param data Matrix to apply ReLU activation function to.
     * @return The result of the ReLU activation function applied to the data matrix.
     */
    @Override
    public Matrix apply(Matrix data) {
<span class="nc" id="L21">        double[][] result = new double[data.numRows()][data.numCols()];</span>
        double value;

<span class="nc bnc" id="L24" title="All 2 branches missed.">        for(int i=0; i&lt;data.numRows(); i++) {</span>
<span class="nc bnc" id="L25" title="All 2 branches missed.">            for(int j=0; j&lt;data.numCols(); j++) {</span>
<span class="nc" id="L26">                value = data.getAsDouble(i, j);</span>
<span class="nc bnc" id="L27" title="All 2 branches missed.">                if(value &gt; 0) {</span>
<span class="nc" id="L28">                    result[i][j] = value;</span>
                } else {
<span class="nc" id="L30">                    result[i][j] = 0;</span>
                }
            }
        }

<span class="nc" id="L35">        return new Matrix(result);</span>
    }


    /**
     * Applies the derivative of the ReLU activation function to a matrix element-wise.
     *
     * @param data Matrix to apply the derivative of the ReLU activation function to.
     * @return The result of the derivative of the ReLU activation function applied to the data matrix.
     */
    @Override
    public Matrix slope(Matrix data) {
<span class="nc" id="L47">        double[][] result = new double[data.numRows()][data.numCols()];</span>
        double value;

<span class="nc bnc" id="L50" title="All 2 branches missed.">        for(int i=0; i&lt;data.numRows(); i++) {</span>
<span class="nc bnc" id="L51" title="All 2 branches missed.">            for(int j=0; j&lt;data.numCols(); j++) {</span>
<span class="nc bnc" id="L52" title="All 2 branches missed.">                if(data.getAsDouble(i, j) &gt; 0) {</span>
<span class="nc" id="L53">                    result[i][j] = 1;</span>
                } else {
<span class="nc" id="L55">                    result[i][j] = 0;</span>
                }
            }
        }

<span class="nc" id="L60">        return new Matrix(result);</span>
    }


    /**
     * Gets the name of the activation function.
     * @return The name of the activation function as a String.
     */
    @Override
<span class="nc" id="L69">    public String getName(){return NAME;}</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.7.202105040129</span></div></body></html>